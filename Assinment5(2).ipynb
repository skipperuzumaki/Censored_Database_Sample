{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assinment5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te4ExzL9Ioco",
        "outputId": "4c63b982-ec20-4d90-dfa4-38cd336c2a24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import random\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"messages.csv\", 'r', encoding=\"utf8\") as f:\n",
        "\tdata = f.read()"
      ],
      "metadata": {
        "id": "iMG4tQLMIyxF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = data.split('\\n')[1:]\n",
        "data2 = [_.split(',')[:2] for _ in data2]\n",
        "random.shuffle(data2)\n",
        "test = data2[0:20]\n",
        "train = data2"
      ],
      "metadata": {
        "id": "Ag87r0FLI4UX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = [word.lower() for passage in train for word in word_tokenize(passage[1])]\n",
        "t = [({word.lower(): dictionary.count(word.lower())+1 for word in word_tokenize(x[1])}, x[0]) for x in train]"
      ],
      "metadata": {
        "id": "fHOC_zn7I6IC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = nltk.NaiveBayesClassifier.train(t)"
      ],
      "metadata": {
        "id": "3L4bdUAuJLup"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr = 0\n",
        "wron = 0\n",
        "all_test_data_features = []\n",
        "for res, abName in test: \n",
        "\ttest_data = abName\n",
        "\ttest_data_features = {word.lower(): dictionary.count(word.lower())+1 for word in test_data}\n",
        "\tall_test_data_features.append(test_data_features)\n",
        "\ttemp = classifier.prob_classify(test_data_features)\n",
        "\tif temp.prob('ham') > temp.prob('spam'):\n",
        "\t\ttemp = 'ham'\n",
        "\telse:\n",
        "\t\ttemp = 'spam'\n",
        "\tprint(temp, res)\n",
        "\tif temp == res:\n",
        "\t\tcorr += 1\n",
        "\telse:\n",
        "\t\twron += 1\n",
        "print(\"accuracy = \" + str(float(corr / (corr+wron))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ7ZxEx4JGo7",
        "outputId": "d319b397-4e41-4e90-d6a2-f3e1cc142fae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ham ham\n",
            "spam spam\n",
            "ham spam\n",
            "spam ham\n",
            "ham spam\n",
            "ham ham\n",
            "ham ham\n",
            "spam spam\n",
            "ham ham\n",
            "ham spam\n",
            "spam spam\n",
            "spam ham\n",
            "spam spam\n",
            "ham ham\n",
            "spam spam\n",
            "spam spam\n",
            "ham ham\n",
            "ham ham\n",
            "spam spam\n",
            "spam spam\n",
            "accuracy = 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx,tdf in enumerate(all_test_data_features):\n",
        "  d = classifier.prob_classify(tdf)\n",
        "  print(test[idx][1][0:10], end = ' > ')\n",
        "  print('ham : ' + str(d.prob('ham')), end = ' | ')\n",
        "  print('spam : ' + str(d.prob('spam')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5ZpqXbPJQDx",
        "outputId": "9f3aca65-491d-41c5-eb6c-7bfd85519791"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I've been  > ham : 7.194638350682051e-12 | spam : 4.96743330477187e-14\n",
            "\"URGENT!:  > ham : 9.51576568392133e-10 | spam : 3.19840610585986e-09\n",
            "\"FreeMsg W > ham : 2.956196527660785e-10 | spam : 1.0244498383632578e-11\n",
            "\"Oops > ham : 0.496296296296296 | spam : 0.496296296296296\n",
            "We tried t > ham : 2.892209267770668e-14 | spam : 1.551140635926241e-14\n",
            "Just force > ham : 3.7445156013790663e-10 | spam : 1.809742397230485e-11\n",
            "I HAVE A D > ham : 8.460468714013663e-07 | spam : 3.0391832911269706e-07\n",
            "0773258435 > ham : 8.50363314681592e-22 | spam : 1.071829362535885e-18\n",
            "Ahhh. Work > ham : 5.449938517314317e-09 | spam : 6.724853850338363e-10\n",
            "Hey I am r > ham : 6.427131706157281e-16 | spam : 4.864204084786265e-16\n",
            "Please cal > ham : 6.930541002619572e-17 | spam : 1.1254124439540438e-13\n",
            "Thats cool > ham : 2.7284143471090182e-08 | spam : 4.6152952114148795e-08\n",
            "Want 2 get > ham : 5.683121162476094e-20 | spam : 3.1907263531596516e-18\n",
            "Do you kno > ham : 8.499796750642617e-11 | spam : 8.607117455685162e-12\n",
            "100 dating > ham : 7.68535239894536e-20 | spam : 7.71120931826494e-18\n",
            "\"FREE RING > ham : 6.364782553425918e-17 | spam : 1.3422016542308604e-13\n",
            "Wah lucky  > ham : 1.5728506989963053e-08 | spam : 9.7900206145493e-09\n",
            "Did you ca > ham : 3.4079865871782323e-12 | spam : 1.7407244914224704e-14\n",
            "\"Urgent UR > ham : 2.0104107095996677e-09 | spam : 2.761287922930074e-09\n",
            "HMV BONUS  > ham : 3.253283893289445e-20 | spam : 1.0253272800498538e-15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomsent = test[0]\n",
        "for word in randomsent[1].split(\" \"):\n",
        "  tdf = {word.lower(): dictionary.count(word.lower())+1}\n",
        "  d = classifier.prob_classify(tdf)\n",
        "  print(word, end = ' > ')\n",
        "  print('ham : ' + str(d.prob('ham')), end = ' | ')\n",
        "  print('spam : ' + str(d.prob('spam')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4EjREcBJ4w1",
        "outputId": "66f507f4-b4f0-4a72-fa86-98d6315942d8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I've > ham : 0.496296296296296 | spam : 0.496296296296296\n",
            "been > ham : 0.36358154959300576 | spam : 0.6059692493216768\n",
            "searching > ham : 0.6310832025117739 | spam : 0.21036106750392464\n",
            "for > ham : 0.3657656071145547 | spam : 0.6253411992603678\n",
            "the > ham : 0.4260949841009331 | spam : 0.563544978972202\n",
            "right > ham : 0.7403314917127068 | spam : 0.14806629834254126\n",
            "words > ham : 0.6310832025117739 | spam : 0.21036106750392464\n",
            "to > ham : 0.3455268563436912 | spam : 0.650059000917792\n",
            "thank > ham : 0.6310832025117739 | spam : 0.21036106750392464\n",
            "you > ham : 0.4806371207976168 | spam : 0.5132226883093196\n",
            "for > ham : 0.3657656071145547 | spam : 0.6253411992603678\n",
            "this > ham : 0.41115760111575966 | spam : 0.5606694560669457\n",
            "breather. > ham : 0.496296296296296 | spam : 0.496296296296296\n",
            "I > ham : 0.878519089857308 | spam : 0.11369070574623975\n",
            "promise > ham : 0.6310832025117739 | spam : 0.21036106750392464\n",
            "i > ham : 0.878519089857308 | spam : 0.11369070574623975\n",
            "wont > ham : 0.6310832025117739 | spam : 0.21036106750392464\n",
            "take > ham : 0.4441988950276243 | spam : 0.4441988950276243\n",
            "your > ham : 0.24125840993082504 | spam : 0.749170851890457\n",
            "help > ham : 0.4441988950276243 | spam : 0.4441988950276243\n",
            "for > ham : 0.3657656071145547 | spam : 0.6253411992603678\n",
            "granted > ham : 0.6310832025117739 | spam : 0.21036106750392464\n",
            "and > ham : 0.4919393455706302 | spam : 0.4919393455706302\n",
            "will > ham : 0.5713348638898001 | spam : 0.3955395211544768\n",
            "fulfil > ham : 0.6310832025117739 | spam : 0.21036106750392464\n",
            "my > ham : 0.8515309069901795 | spam : 0.12901983439245152\n",
            "promise. > ham : 0.496296296296296 | spam : 0.496296296296296\n",
            "You > ham : 0.4806371207976168 | spam : 0.5132226883093196\n",
            "have > ham : 0.37001972386587767 | spam : 0.6166995397764627\n",
            "been > ham : 0.36358154959300576 | spam : 0.6059692493216768\n",
            "wonderful > ham : 0.6310832025117739 | spam : 0.21036106750392464\n",
            "and > ham : 0.4919393455706302 | spam : 0.4919393455706302\n",
            "a > ham : 0.34021821176147676 | spam : 0.6528511631098608\n",
            "blessing > ham : 0.6310832025117739 | spam : 0.21036106750392464\n",
            "at > ham : 0.7227615965480043 | spam : 0.24092053218266812\n",
            "all > ham : 0.7675610491407899 | spam : 0.20198974977389228\n",
            "times. > ham : 0.496296296296296 | spam : 0.496296296296296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(all_test_data_features[0])\n",
        "temp = classifier.prob_classify(tdf)\n",
        "if temp.prob('ham') > temp.prob('spam'):\n",
        "  temp = 'ham'\n",
        "else:\n",
        "  temp = 'spam'\n",
        "temp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "TLaixpH-NelC",
        "outputId": "c7cc4bef-8bcb-4f73-f273-ceef5c9600f0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'spam'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}